import os
from bs4 import BeautifulSoup

TARGET_FILE = 'index.html'

new_papers = [
    {
        "title": "AI, Information Depth, and the Collapse of Shallow Signal Predictability: Evidence from a 40-Year Structural Break in Equity Markets",
        "date": "February 08, 2026",
        "link": "https://ssrn.com/abstract=6195878",
        "author": "Huang, Po-Sung (Sinclair)"
    },
    {
        "title": "Architectural Trade-Offs in Vision-Only FSD and Sensor-Fusion Chip Design: Memory Bandwidth, Cache Capacity, and Competitive Dynamics in Autonomous Driving Semiconductors",
        "date": "February 05, 2026",
        "link": "https://ssrn.com/abstract=6184459",
        "author": "Huang, Po-Sung (Sinclair)"
    },
    {
        "title": "Patent Quality Versus Quantity in the Intangible Economy: A Cross-Industry Empirical Analysis of Innovation-Driven Market Valuation",
        "date": "January 31, 2026",
        "link": "https://ssrn.com/abstract=6157046",
        "author": "Huang, Po-Sung (Sinclair)"
    }
]

def update_website():
    if not os.path.exists(TARGET_FILE):
        print(f"âŒ é€™è£¡ä¹Ÿæ²’æœ‰ '{TARGET_FILE}'ã€‚")
        print("çœ‹ä¾†é€™å€‹è³‡æ–™å¤¾ä¹Ÿä¸æ˜¯æ­£ç¢ºçš„ç¶²ç«™ä½ç½®ã€‚è«‹å†è©¦è©¦çœ‹åˆ¥çš„è³‡æ–™å¤¾ã€‚")
        return

    with open(TARGET_FILE, 'r', encoding='utf-8') as file:
        soup = BeautifulSoup(file, 'html.parser')

    # å˜—è©¦ 1: æ‰¾ id="publications-list"
    pub_list = soup.find('ul', {'id': 'publications-list'}) 
    
    # å˜—è©¦ 2: æ‰¾æ¨™é¡ŒåŒ…å« "Publication" ä¸‹é¢çš„ç¬¬ä¸€å€‹åˆ—è¡¨
    if not pub_list:
        headers = soup.find_all(['h1', 'h2', 'h3', 'h4'])
        for header in headers:
            if 'Publication' in header.get_text() or 'Research' in header.get_text():
                pub_list = header.find_next('ul')
                if pub_list: break
    
    # å˜—è©¦ 3 (æš´åŠ›æ³•): çœŸçš„æ‰¾ä¸åˆ°ï¼Œå°±ç›´æ¥æ’åœ¨ body çš„æœ€å‰é¢ï¼Œè®“æ‚¨æ‰‹å‹•æ¬
    inserted_location = "åˆ—è¡¨"
    if not pub_list:
        print("âš ï¸  æ‰¾ä¸åˆ°æ¨™æº–åˆ—è¡¨ï¼Œå°‡æš«æ™‚æ’å…¥åˆ°é é¢æœ€ä¸Šæ–¹ (Body Start)...")
        pub_list = soup.body
        inserted_location = "é é¢æœ€ä¸Šæ–¹"
        if not pub_list:
             print("âŒ éŒ¯èª¤ï¼šé€™å€‹ HTML æª”æ¡ˆçµæ§‹å¤ªå¥‡æ€ªäº†ï¼Œæ‰¾ä¸åˆ° bodyã€‚")
             return

    print(f"âœ… æº–å‚™å°‡ {len(new_papers)} ç¯‡è«–æ–‡æ’å…¥åˆ° {inserted_location}...")

    # æº–å‚™ä¸€å€‹å®¹å™¨ä¾†è£æ–°è«–æ–‡
    container = soup.new_tag("ul") if inserted_location == "é é¢æœ€ä¸Šæ–¹" else None

    for paper in reversed(new_papers):
        new_li = soup.new_tag("li")
        link_tag = soup.new_tag("a", href=paper["link"], target="_blank")
        link_tag.string = paper["title"]
        date_span = soup.new_tag("span", style="color: #666; margin-left: 10px;")
        date_span.string = f"({paper['date']})"
        
        new_li.append(link_tag)
        new_li.append(date_span)
        
        if container:
            container.append(new_li)
        else:
            pub_list.insert(0, new_li)

    if container:
        pub_list.insert(0, container)

    with open(TARGET_FILE, 'w', encoding='utf-8') as file:
        file.write(str(soup.prettify()))

    print(f"ğŸ‰ æ›´æ–°æˆåŠŸï¼è«‹æ‰“é–‹ {TARGET_FILE} ç¢ºèªçµæœã€‚")

if __name__ == "__main__":
    update_website()
