import feedparser
from bs4 import BeautifulSoup
import datetime
import os

# è¨­å®šæ‚¨çš„æ–°èé é¢è·¯å¾‘ (å‡è¨­æ˜¯ docs/news/index.html)
# å¦‚æœç¨‹å¼èªªæ‰¾ä¸åˆ°ï¼Œè«‹ç¢ºèªå¯¦éš›è·¯å¾‘
TARGET_FILE = 'docs/news/index.html'

RSS_FEEDS = [
    {
        "category": "AI & Semiconductors",
        "url": "https://news.google.com/rss/search?q=Semiconductor+OR+Nvidia+OR+TSMC+OR+AI+Chip+when:7d&hl=en-US&gl=US&ceid=US:en"
    },
    {
        "category": "Biotech & AI",
        "url": "https://news.google.com/rss/search?q=Biotech+AI+OR+AlphaFold+OR+Generative+Biology+when:7d&hl=en-US&gl=US&ceid=US:en"
    }
]

def update_news_page():
    if not os.path.exists(TARGET_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™æª”æ¡ˆï¼š{TARGET_FILE}")
        print("è«‹æª¢æŸ¥æ‚¨çš„æ–°èé é¢ index.html åˆ°åº•åœ¨å“ªå€‹è³‡æ–™å¤¾ï¼Ÿ(ä¾‹å¦‚ docs/ é‚„æ˜¯ content/ï¼Ÿ)")
        return

    print("ğŸ“¡ æ­£åœ¨å¾ Google News æŠ“å–æœ€æ–°æ¨™é¡Œ...")
    news_items = []
    
    for feed in RSS_FEEDS:
        print(f"   - è®€å–: {feed['category']} ...")
        d = feedparser.parse(feed['url'])
        for entry in d.entries[:3]:
            news_items.append({
                "title": entry.title,
                "link": entry.link,
                "date": datetime.datetime.now().strftime("%Y-%m-%d"),
                "source": entry.source.title if 'source' in entry else "Google News"
            })

    with open(TARGET_FILE, 'r', encoding='utf-8') as file:
        soup = BeautifulSoup(file, 'html.parser')

    # å°‹æ‰¾æ–°èå€å¡Š (æ¨™é¡Œå«æœ‰ Industry News æˆ– Latest)
    news_header = None
    for h in soup.find_all(['h1', 'h2', 'h3', 'div']):
        if 'Industry News' in h.get_text() or 'Latest Industry News' in h.get_text():
            news_header = h
            break
    
    if not news_header:
        print("âŒ æ‰¾ä¸åˆ° 'Industry News' æ¨™é¡Œï¼Œç„¡æ³•å®šä½æ’å…¥é»ã€‚")
        return

    # å˜—è©¦æ‰¾åˆ°æ¨™é¡Œå¾Œçš„åˆ—è¡¨å®¹å™¨
    news_container = news_header.find_next(['ul', 'div'])
    
    if not news_container:
        news_container = soup.new_tag('ul')
        news_header.insert_after(news_container)
    else:
        news_container.clear() # æ¸…ç©ºèˆŠæ–°è

    print(f"ğŸ“ æ­£åœ¨å¯«å…¥ {len(news_items)} å‰‡æœ€æ–°æ–°è...")
    
    if news_container.name != 'ul':
        new_ul = soup.new_tag('ul')
        news_container.append(new_ul)
        news_container = new_ul

    for item in news_items:
        li = soup.new_tag('li')
        li['style'] = "margin-bottom: 20px; list-style: none;"
        
        a = soup.new_tag('a', href=item['link'], target="_blank")
        a.string = item['title']
        a['style'] = "font-weight: 600; color: #2c3e50; text-decoration: none; font-size: 1.1em;"
        
        meta = soup.new_tag('div')
        meta.string = f"{item['source']} â€¢ {item['date']}"
        meta['style'] = "font-size: 0.85em; color: #7f8c8d; margin-top: 4px;"

        li.append(a)
        li.append(meta)
        news_container.append(li)

    with open(TARGET_FILE, 'w', encoding='utf-8') as file:
        file.write(str(soup.prettify()))

    print("ğŸ‰ æ–°èé é¢æ›´æ–°æˆåŠŸï¼")

if __name__ == "__main__":
    update_news_page()
